"""
é‡‡æ ·è´¨é‡éªŒè¯å·¥å…·

ç”¨äºéªŒè¯æ•°æ®é‡‡æ ·ç»“æœæ˜¯å¦æ»¡è¶³98% F1å¾®è°ƒç›®æ ‡çš„è¦æ±‚

ç”¨æ³•:
    python validate_sampling_quality.py --input data/sampled_15k.csv --stats data/sampled_15k_stats.json
"""

import pandas as pd
import numpy as np
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple


class SamplingQualityValidator:
    """é‡‡æ ·è´¨é‡éªŒè¯å™¨"""
    
    # è´¨é‡é˜ˆå€¼ï¼ˆé’ˆå¯¹98% F1ç›®æ ‡ï¼‰
    THRESHOLDS = {
        'coverage_rate': 0.95,      # ç°‡è¦†ç›–ç‡ â‰¥ 95%
        'normalized_entropy': 0.80,  # æ ‡å‡†åŒ–ç†µ â‰¥ 0.80
        'mean_quality': 0.50,        # å¹³å‡è´¨é‡ â‰¥ 0.50
        'min_samples': 15000,        # æœ€å°æ ·æœ¬æ•°
        'min_per_cluster': 3,        # æ¯ç°‡æœ€å°‘æ ·æœ¬æ•°
        'max_per_cluster_ratio': 0.10 # å•ç°‡æœ€å¤šå æ¯” â‰¤ 10%
    }
    
    def __init__(self, data_file: str, stats_file: str = None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        å‚æ•°:
        - data_file: é‡‡æ ·æ•°æ®æ–‡ä»¶è·¯å¾„
        - stats_file: ç»Ÿè®¡æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.data_file = data_file
        self.stats_file = stats_file or data_file.replace('.csv', '_stats.json')
        
        # åŠ è½½æ•°æ®
        self.df = pd.read_csv(data_file)
        
        # åŠ è½½ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self.stats = None
        if Path(self.stats_file).exists():
            with open(self.stats_file, 'r', encoding='utf-8') as f:
                self.stats = json.load(f)
    
    def validate_all(self) -> Dict[str, any]:
        """
        æ‰§è¡Œæ‰€æœ‰éªŒè¯æ£€æŸ¥
        
        è¿”å›:
        - results: éªŒè¯ç»“æœå­—å…¸
        """
        print("=" * 70)
        print("é‡‡æ ·è´¨é‡éªŒè¯ - 98% F1ç›®æ ‡")
        print("=" * 70)
        print(f"æ•°æ®æ–‡ä»¶: {self.data_file}")
        print(f"ç»Ÿè®¡æ–‡ä»¶: {self.stats_file}")
        print()
        
        results = {
            'file': self.data_file,
            'checks': [],
            'passed': 0,
            'failed': 0,
            'warnings': 0,
            'overall_status': 'UNKNOWN'
        }
        
        # 1. æ•°æ®é‡æ£€æŸ¥
        results['checks'].append(self._check_sample_size())
        
        # 2. ç°‡è¦†ç›–ç‡æ£€æŸ¥
        results['checks'].append(self._check_cluster_coverage())
        
        # 3. å¤šæ ·æ€§æ£€æŸ¥
        results['checks'].append(self._check_diversity())
        
        # 4. è´¨é‡æ£€æŸ¥
        results['checks'].append(self._check_quality())
        
        # 5. ç°‡å¹³è¡¡æ€§æ£€æŸ¥
        results['checks'].append(self._check_cluster_balance())
        
        # 6. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        results['checks'].append(self._check_data_integrity())
        
        # ç»Ÿè®¡ç»“æœ
        for check in results['checks']:
            if check['status'] == 'PASS':
                results['passed'] += 1
            elif check['status'] == 'FAIL':
                results['failed'] += 1
            else:
                results['warnings'] += 1
        
        # åˆ¤æ–­æ€»ä½“çŠ¶æ€
        if results['failed'] == 0:
            if results['warnings'] == 0:
                results['overall_status'] = 'EXCELLENT'
            else:
                results['overall_status'] = 'GOOD'
        elif results['failed'] <= 2:
            results['overall_status'] = 'ACCEPTABLE'
        else:
            results['overall_status'] = 'NEEDS_IMPROVEMENT'
        
        # æ‰“å°æ€»ç»“
        self._print_summary(results)
        
        return results
    
    def _check_sample_size(self) -> Dict:
        """æ£€æŸ¥æ ·æœ¬æ•°é‡"""
        n_samples = len(self.df)
        threshold = self.THRESHOLDS['min_samples']
        
        check = {
            'name': 'æ ·æœ¬æ•°é‡',
            'value': n_samples,
            'threshold': f'>= {threshold}',
            'status': 'PASS' if n_samples >= threshold else 'WARN',
            'message': ''
        }
        
        if n_samples >= 20000:
            check['message'] = f'âœ“ æ ·æœ¬æ•°é‡å……è¶³ ({n_samples:,}æ¡)ï¼Œé€‚åˆå¤§æ¨¡å‹å¾®è°ƒ'
        elif n_samples >= threshold:
            check['message'] = f'âœ“ æ ·æœ¬æ•°é‡è¾¾æ ‡ ({n_samples:,}æ¡)ï¼Œå»ºè®®å¢åŠ åˆ°20000æ¡ä»¥è·å¾—æ›´å¥½æ•ˆæœ'
        else:
            check['status'] = 'WARN'
            check['message'] = f'âš ï¸ æ ·æœ¬æ•°é‡ä¸è¶³ ({n_samples:,}æ¡)ï¼Œå»ºè®®è‡³å°‘{threshold:,}æ¡'
        
        print(f"1. {check['name']}: {check['message']}")
        return check
    
    def _check_cluster_coverage(self) -> Dict:
        """æ£€æŸ¥ç°‡è¦†ç›–ç‡"""
        if 'cluster_id' not in self.df.columns:
            return {
                'name': 'ç°‡è¦†ç›–ç‡',
                'value': 'N/A',
                'threshold': 'N/A',
                'status': 'WARN',
                'message': 'âš ï¸ ç¼ºå°‘cluster_idåˆ—ï¼Œæ— æ³•éªŒè¯ç°‡è¦†ç›–ç‡'
            }
        
        # ä»ç»Ÿè®¡æ–‡ä»¶è·å–è¦†ç›–ç‡
        if self.stats and 'clustering_stats' in self.stats:
            coverage_rate = self.stats['clustering_stats']['coverage_rate_final']
            n_covered = self.stats['clustering_stats']['n_covered_clusters_final']
            n_total = self.stats['clustering_stats']['n_active_clusters']
        else:
            # ä»æ•°æ®æ¨æ–­
            n_covered = self.df['cluster_id'].nunique()
            n_total = n_covered  # æ— æ³•çŸ¥é“æ€»æ•°
            coverage_rate = 1.0
        
        threshold = self.THRESHOLDS['coverage_rate']
        
        check = {
            'name': 'ç°‡è¦†ç›–ç‡',
            'value': coverage_rate,
            'threshold': f'>= {threshold:.0%}',
            'status': 'PASS' if coverage_rate >= threshold else 'FAIL',
            'message': ''
        }
        
        if coverage_rate >= 0.98:
            check['message'] = f'âœ“ ç°‡è¦†ç›–ç‡ä¼˜ç§€ ({coverage_rate:.1%}, {n_covered}/{n_total})'
        elif coverage_rate >= threshold:
            check['message'] = f'âœ“ ç°‡è¦†ç›–ç‡è‰¯å¥½ ({coverage_rate:.1%}, {n_covered}/{n_total})'
        else:
            check['status'] = 'FAIL'
            check['message'] = f'âŒ ç°‡è¦†ç›–ç‡ä¸è¶³ ({coverage_rate:.1%}, {n_covered}/{n_total})ï¼Œéœ€è¦æé«˜'
        
        print(f"2. {check['name']}: {check['message']}")
        return check
    
    def _check_diversity(self) -> Dict:
        """æ£€æŸ¥æ•°æ®å¤šæ ·æ€§ï¼ˆShannonç†µï¼‰"""
        if 'cluster_id' not in self.df.columns:
            return {
                'name': 'æ•°æ®å¤šæ ·æ€§',
                'value': 'N/A',
                'threshold': 'N/A',
                'status': 'WARN',
                'message': 'âš ï¸ ç¼ºå°‘cluster_idåˆ—ï¼Œæ— æ³•éªŒè¯å¤šæ ·æ€§'
            }
        
        # è®¡ç®—Shannonç†µ
        cluster_counts = self.df['cluster_id'].value_counts()
        cluster_probs = cluster_counts / cluster_counts.sum()
        shannon_entropy = -np.sum(cluster_probs * np.log(cluster_probs + 1e-10))
        max_entropy = np.log(len(cluster_counts))
        normalized_entropy = shannon_entropy / max_entropy if max_entropy > 0 else 0
        
        threshold = self.THRESHOLDS['normalized_entropy']
        
        check = {
            'name': 'æ•°æ®å¤šæ ·æ€§',
            'value': normalized_entropy,
            'threshold': f'>= {threshold:.2f}',
            'status': 'PASS' if normalized_entropy >= threshold else 'WARN',
            'message': ''
        }
        
        if normalized_entropy >= 0.90:
            check['message'] = f'âœ“ åˆ†å¸ƒéå¸¸å‡åŒ€ (ç†µ={normalized_entropy:.3f})'
        elif normalized_entropy >= threshold:
            check['message'] = f'âœ“ åˆ†å¸ƒè¾ƒå‡åŒ€ (ç†µ={normalized_entropy:.3f})'
        else:
            check['status'] = 'WARN'
            check['message'] = f'âš ï¸ åˆ†å¸ƒä¸å¤Ÿå‡åŒ€ (ç†µ={normalized_entropy:.3f})ï¼ŒæŸäº›ç°‡å¯èƒ½è¿‡åº¦ä»£è¡¨'
        
        print(f"3. {check['name']}: {check['message']}")
        return check
    
    def _check_quality(self) -> Dict:
        """æ£€æŸ¥è´¨é‡å¾—åˆ†"""
        if 'quality_score' not in self.df.columns:
            return {
                'name': 'è´¨é‡å¾—åˆ†',
                'value': 'N/A',
                'threshold': 'N/A',
                'status': 'WARN',
                'message': 'âš ï¸ ç¼ºå°‘quality_scoreåˆ—ï¼Œæ— æ³•éªŒè¯è´¨é‡'
            }
        
        mean_quality = self.df['quality_score'].mean()
        min_quality = self.df['quality_score'].min()
        threshold = self.THRESHOLDS['mean_quality']
        
        check = {
            'name': 'è´¨é‡å¾—åˆ†',
            'value': mean_quality,
            'threshold': f'>= {threshold:.2f}',
            'status': 'PASS' if mean_quality >= threshold else 'WARN',
            'message': ''
        }
        
        if mean_quality >= 0.70:
            check['message'] = f'âœ“ è´¨é‡ä¼˜ç§€ (å¹³å‡={mean_quality:.3f}, æœ€ä½={min_quality:.3f})'
        elif mean_quality >= threshold:
            check['message'] = f'âœ“ è´¨é‡è‰¯å¥½ (å¹³å‡={mean_quality:.3f}, æœ€ä½={min_quality:.3f})'
        else:
            check['status'] = 'WARN'
            check['message'] = f'âš ï¸ è´¨é‡åä½ (å¹³å‡={mean_quality:.3f})ï¼Œå¯èƒ½éœ€è¦æ”¹è¿›è¯„åˆ†è§„åˆ™'
        
        print(f"4. {check['name']}: {check['message']}")
        return check
    
    def _check_cluster_balance(self) -> Dict:
        """æ£€æŸ¥ç°‡å¹³è¡¡æ€§"""
        if 'cluster_id' not in self.df.columns:
            return {
                'name': 'ç°‡å¹³è¡¡æ€§',
                'value': 'N/A',
                'threshold': 'N/A',
                'status': 'WARN',
                'message': 'âš ï¸ ç¼ºå°‘cluster_idåˆ—ï¼Œæ— æ³•éªŒè¯å¹³è¡¡æ€§'
            }
        
        cluster_counts = self.df['cluster_id'].value_counts()
        min_count = cluster_counts.min()
        max_count = cluster_counts.max()
        mean_count = cluster_counts.mean()
        max_ratio = max_count / len(self.df)
        
        min_threshold = self.THRESHOLDS['min_per_cluster']
        max_threshold = self.THRESHOLDS['max_per_cluster_ratio']
        
        check = {
            'name': 'ç°‡å¹³è¡¡æ€§',
            'value': f'{min_count}-{max_count}',
            'threshold': f'æ¯ç°‡ >= {min_threshold}, å•ç°‡ <= {max_threshold:.0%}',
            'status': 'PASS',
            'message': ''
        }
        
        issues = []
        
        if min_count < min_threshold:
            check['status'] = 'WARN'
            issues.append(f'æœ€å°ç°‡ä»…{min_count}æ¡')
        
        if max_ratio > max_threshold:
            check['status'] = 'WARN'
            issues.append(f'æœ€å¤§ç°‡å {max_ratio:.1%}')
        
        if issues:
            check['message'] = f'âš ï¸ ç°‡ä¸å¹³è¡¡: {", ".join(issues)} (èŒƒå›´: {min_count}-{max_count}, å¹³å‡: {mean_count:.1f})'
        else:
            check['message'] = f'âœ“ ç°‡å¹³è¡¡è‰¯å¥½ (èŒƒå›´: {min_count}-{max_count}, å¹³å‡: {mean_count:.1f})'
        
        print(f"5. {check['name']}: {check['message']}")
        return check
    
    def _check_data_integrity(self) -> Dict:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        issues = []
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['text']
        missing_cols = [col for col in required_cols if col not in self.df.columns]
        if missing_cols:
            issues.append(f'ç¼ºå°‘åˆ—: {", ".join(missing_cols)}')
        
        # æ£€æŸ¥ç©ºå€¼
        if 'text' in self.df.columns:
            null_count = self.df['text'].isnull().sum()
            if null_count > 0:
                issues.append(f'{null_count}æ¡æ–‡æœ¬ä¸ºç©º')
        
        # æ£€æŸ¥é‡å¤
        if 'text' in self.df.columns:
            dup_count = self.df['text'].duplicated().sum()
            if dup_count > 0:
                issues.append(f'{dup_count}æ¡é‡å¤æ–‡æœ¬')
        
        # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
        if 'text' in self.df.columns:
            text_lengths = self.df['text'].str.len()
            too_short = (text_lengths < 3).sum()
            too_long = (text_lengths > 500).sum()
            if too_short > 0:
                issues.append(f'{too_short}æ¡æ–‡æœ¬è¿‡çŸ­(<3å­—ç¬¦)')
            if too_long > 0:
                issues.append(f'{too_long}æ¡æ–‡æœ¬è¿‡é•¿(>500å­—ç¬¦)')
        
        check = {
            'name': 'æ•°æ®å®Œæ•´æ€§',
            'value': f'{len(issues)} ä¸ªé—®é¢˜',
            'threshold': '0 ä¸ªé—®é¢˜',
            'status': 'PASS' if len(issues) == 0 else 'WARN',
            'message': ''
        }
        
        if issues:
            check['message'] = f'âš ï¸ å‘ç°é—®é¢˜: {"; ".join(issues)}'
        else:
            check['message'] = 'âœ“ æ•°æ®å®Œæ•´ï¼Œæ— æ˜æ˜¾é—®é¢˜'
        
        print(f"6. {check['name']}: {check['message']}")
        return check
    
    def _print_summary(self, results: Dict):
        """æ‰“å°éªŒè¯æ€»ç»“"""
        print()
        print("=" * 70)
        print("éªŒè¯æ€»ç»“")
        print("=" * 70)
        print(f"é€šè¿‡: {results['passed']} é¡¹")
        print(f"è­¦å‘Š: {results['warnings']} é¡¹")
        print(f"å¤±è´¥: {results['failed']} é¡¹")
        print()
        
        status_emoji = {
            'EXCELLENT': 'ğŸ‰',
            'GOOD': 'âœ…',
            'ACCEPTABLE': 'âš ï¸',
            'NEEDS_IMPROVEMENT': 'âŒ'
        }
        
        status_msg = {
            'EXCELLENT': 'ä¼˜ç§€ï¼æ•°æ®è´¨é‡å®Œå…¨æ»¡è¶³98% F1ç›®æ ‡',
            'GOOD': 'è‰¯å¥½ï¼æ•°æ®è´¨é‡åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œå¯ä»¥å¼€å§‹æ ‡æ³¨å’Œè®­ç»ƒ',
            'ACCEPTABLE': 'å¯æ¥å—ï¼Œä½†å»ºè®®æ”¹è¿›éƒ¨åˆ†æŒ‡æ ‡ä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœ',
            'NEEDS_IMPROVEMENT': 'éœ€è¦æ”¹è¿›ï¼è¯·æ ¹æ®ä¸Šè¿°å»ºè®®è°ƒæ•´é‡‡æ ·å‚æ•°'
        }
        
        overall_status = results['overall_status']
        print(f"æ€»ä½“è¯„ä»·: {status_emoji[overall_status]} {overall_status}")
        print(f"{status_msg[overall_status]}")
        print("=" * 70)
        
        # ç»™å‡ºå»ºè®®
        if results['failed'] > 0 or results['warnings'] > 0:
            print()
            print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            
            for check in results['checks']:
                if check['status'] in ['FAIL', 'WARN']:
                    print(f"\nâ€¢ {check['name']}: {check['message']}")
                    
                    # æ ¹æ®ä¸åŒé—®é¢˜ç»™å‡ºå…·ä½“å»ºè®®
                    if check['name'] == 'æ ·æœ¬æ•°é‡' and check['status'] == 'WARN':
                        print("  â†’ é‡æ–°è¿è¡Œé‡‡æ ·ï¼Œå¢åŠ  --n_samples åˆ° 15000-20000")
                    
                    elif check['name'] == 'ç°‡è¦†ç›–ç‡' and check['status'] == 'FAIL':
                        print("  â†’ å¢åŠ  --min_per_cluster åˆ° 10")
                        print("  â†’ æˆ–å‡å°‘ --n_clusters")
                    
                    elif check['name'] == 'æ•°æ®å¤šæ ·æ€§' and check['status'] == 'WARN':
                        print("  â†’ ä½¿ç”¨ --sampling_strategy balanced")
                        print("  â†’ å¢åŠ  --min_per_cluster")
                    
                    elif check['name'] == 'è´¨é‡å¾—åˆ†' and check['status'] == 'WARN':
                        print("  â†’ è°ƒæ•´QualityScorerçš„è¯„åˆ†æƒé‡")
                        print("  â†’ åŠ å¼ºæ•°æ®æ¸…æ´—")
            
            print()
    
    def export_report(self, output_file: str = None):
        """å¯¼å‡ºéªŒè¯æŠ¥å‘Š"""
        if output_file is None:
            output_file = self.data_file.replace('.csv', '_validation_report.json')
        
        results = self.validate_all()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, indent=2, fp=f, ensure_ascii=False)
        
        print(f"\néªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        return output_file


def main():
    parser = argparse.ArgumentParser(
        description="é‡‡æ ·è´¨é‡éªŒè¯å·¥å…· - éªŒè¯æ˜¯å¦æ»¡è¶³98% F1ç›®æ ‡",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="é‡‡æ ·æ•°æ®æ–‡ä»¶è·¯å¾„ (CSV)"
    )
    parser.add_argument(
        "--stats",
        type=str,
        default=None,
        help="ç»Ÿè®¡æ–‡ä»¶è·¯å¾„ (JSON, å¯é€‰)"
    )
    parser.add_argument(
        "--export",
        action="store_true",
        help="æ˜¯å¦å¯¼å‡ºéªŒè¯æŠ¥å‘Š"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºéªŒè¯å™¨å¹¶è¿è¡Œ
    validator = SamplingQualityValidator(args.input, args.stats)
    
    if args.export:
        validator.export_report()
    else:
        validator.validate_all()


if __name__ == "__main__":
    main()

